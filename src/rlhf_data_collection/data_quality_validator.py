"""
RLHFæ•°æ®è´¨é‡éªŒè¯å™¨
å®ç°æ•°æ®éªŒè¯ã€å¼‚å¸¸æ£€æµ‹å’Œè´¨é‡æ§åˆ¶åŠŸèƒ½
"""

import logging
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import json

logger = logging.getLogger(__name__)

class RLHFDataQualityValidator:
    """RLHFæ•°æ®è´¨é‡éªŒè¯å™¨"""
    
    def __init__(self, config_manager):
        """
        åˆå§‹åŒ–æ•°æ®è´¨é‡éªŒè¯å™¨
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨
        """
        self.config_manager = config_manager
        
        # åŠ è½½æ•°æ®è´¨é‡é…ç½®
        self.quality_config = config_manager.config.get('data_quality', {})
        
        # éªŒè¯è§„åˆ™é…ç½®
        self.validation_rules = self.quality_config.get('validation_rules', {})
        self.completeness_checks = self.quality_config.get('completeness_checks', {})
        self.anomaly_detection = self.quality_config.get('anomaly_detection', {})
        
        # ç‰©ç†çº¦æŸé…ç½®
        self.physical_constraints = {
            'position_bounds': {
                'min_altitude': 200.0,  # km
                'max_altitude': 50000.0,  # km
                'earth_radius': 6371.0  # km
            },
            'velocity_limits': {
                'max_orbital_velocity': 15.0,  # km/s
                'max_missile_velocity': 8.0   # km/s
            },
            'attitude_constraints': {
                'quaternion_norm_tolerance': 0.01
            },
            'temporal_constraints': {
                'max_time_gap': 3600.0,  # ç§’
                'min_time_step': 1.0     # ç§’
            }
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.validation_stats = {
            'total_validations': 0,
            'passed_validations': 0,
            'failed_validations': 0,
            'anomaly_detections': 0,
            'data_quality_score': 1.0
        }
        
        # å†å²æ•°æ®ç”¨äºå¼‚å¸¸æ£€æµ‹
        self.historical_data = []
        self.max_history_size = 1000
        
        logger.info("ğŸ” RLHFæ•°æ®è´¨é‡éªŒè¯å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def validate_rlhf_data_point(self, data_point) -> Dict[str, Any]:
        """
        éªŒè¯RLHFæ•°æ®ç‚¹
        
        Args:
            data_point: RLHFæ•°æ®ç‚¹
            
        Returns:
            éªŒè¯ç»“æœ
        """
        try:
            validation_result = {
                'is_valid': True,
                'validation_score': 1.0,
                'errors': [],
                'warnings': [],
                'anomalies': [],
                'quality_metrics': {}
            }
            
            # æ›´æ–°ç»Ÿè®¡
            self.validation_stats['total_validations'] += 1
            
            # 1. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
            completeness_result = self._check_data_completeness(data_point)
            validation_result['quality_metrics']['completeness'] = completeness_result
            
            if not completeness_result['is_complete']:
                validation_result['is_valid'] = False
                validation_result['errors'].extend(completeness_result['missing_fields'])
            
            # 2. æ•°æ®æ ¼å¼éªŒè¯
            format_result = self._validate_data_format(data_point)
            validation_result['quality_metrics']['format'] = format_result
            
            if not format_result['is_valid']:
                validation_result['is_valid'] = False
                validation_result['errors'].extend(format_result['format_errors'])
            
            # 3. ç‰©ç†çº¦æŸæ£€æŸ¥
            physics_result = self._check_physical_constraints(data_point)
            validation_result['quality_metrics']['physics'] = physics_result
            
            if not physics_result['is_valid']:
                validation_result['warnings'].extend(physics_result['constraint_violations'])
            
            # 4. æ—¶é—´ä¸€è‡´æ€§æ£€æŸ¥
            temporal_result = self._check_temporal_consistency(data_point)
            validation_result['quality_metrics']['temporal'] = temporal_result
            
            if not temporal_result['is_consistent']:
                validation_result['warnings'].extend(temporal_result['inconsistencies'])
            
            # 5. å¼‚å¸¸æ£€æµ‹
            if self.anomaly_detection.get('statistical_outliers', False):
                anomaly_result = self._detect_anomalies(data_point)
                validation_result['anomalies'] = anomaly_result['anomalies']
                validation_result['quality_metrics']['anomaly_score'] = anomaly_result['anomaly_score']
                
                if anomaly_result['anomalies']:
                    self.validation_stats['anomaly_detections'] += 1
            
            # 6. è®¡ç®—æ€»ä½“è´¨é‡åˆ†æ•°
            validation_result['validation_score'] = self._calculate_quality_score(validation_result)
            
            # æ›´æ–°ç»Ÿè®¡
            if validation_result['is_valid']:
                self.validation_stats['passed_validations'] += 1
            else:
                self.validation_stats['failed_validations'] += 1
            
            # æ›´æ–°å†å²æ•°æ®
            self._update_historical_data(data_point, validation_result)
            
            logger.debug(f"æ•°æ®éªŒè¯å®Œæˆ: æœ‰æ•ˆ={validation_result['is_valid']}, "
                        f"åˆ†æ•°={validation_result['validation_score']:.3f}")
            
            return validation_result
            
        except Exception as e:
            logger.error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
            return {
                'is_valid': False,
                'validation_score': 0.0,
                'errors': [f'validation_error: {str(e)}'],
                'warnings': [],
                'anomalies': [],
                'quality_metrics': {}
            }
    
    def _check_data_completeness(self, data_point) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        try:
            required_fields = self.completeness_checks.get('required_fields', [])
            optional_fields = self.completeness_checks.get('optional_fields', [])
            missing_threshold = self.completeness_checks.get('missing_data_threshold', 0.05)
            
            missing_fields = []
            present_fields = []
            
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            for field in required_fields:
                if self._check_field_exists(data_point, field):
                    present_fields.append(field)
                else:
                    missing_fields.append(field)
            
            # æ£€æŸ¥å¯é€‰å­—æ®µ
            optional_present = 0
            for field in optional_fields:
                if self._check_field_exists(data_point, field):
                    optional_present += 1
            
            # è®¡ç®—å®Œæ•´æ€§åˆ†æ•°
            required_completeness = len(present_fields) / len(required_fields) if required_fields else 1.0
            optional_completeness = optional_present / len(optional_fields) if optional_fields else 1.0
            
            overall_completeness = 0.8 * required_completeness + 0.2 * optional_completeness
            
            is_complete = (len(missing_fields) == 0 and 
                          overall_completeness >= (1.0 - missing_threshold))
            
            return {
                'is_complete': is_complete,
                'completeness_score': overall_completeness,
                'missing_fields': missing_fields,
                'present_fields': present_fields,
                'required_completeness': required_completeness,
                'optional_completeness': optional_completeness
            }
            
        except Exception as e:
            logger.error(f"å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return {
                'is_complete': False,
                'completeness_score': 0.0,
                'missing_fields': ['completeness_check_error'],
                'present_fields': []
            }
    
    def _validate_data_format(self, data_point) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®æ ¼å¼"""
        try:
            format_errors = []
            
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            if not hasattr(data_point, 'state') or not hasattr(data_point, 'action'):
                format_errors.append('missing_basic_structure')
            
            # æ£€æŸ¥çŠ¶æ€æ ¼å¼
            if hasattr(data_point, 'state'):
                state_errors = self._validate_state_format(data_point.state)
                format_errors.extend(state_errors)
            
            # æ£€æŸ¥åŠ¨ä½œæ ¼å¼
            if hasattr(data_point, 'action'):
                action_errors = self._validate_action_format(data_point.action)
                format_errors.extend(action_errors)
            
            # æ£€æŸ¥å¥–åŠ±æ ¼å¼
            if hasattr(data_point, 'reward'):
                if not isinstance(data_point.reward, (int, float)):
                    format_errors.append('invalid_reward_type')
                elif not np.isfinite(data_point.reward):
                    format_errors.append('invalid_reward_value')
            
            # æ£€æŸ¥æ—¶é—´æˆ³æ ¼å¼
            if hasattr(data_point, 'timestamp'):
                if not isinstance(data_point.timestamp, datetime):
                    format_errors.append('invalid_timestamp_type')
            
            return {
                'is_valid': len(format_errors) == 0,
                'format_errors': format_errors
            }
            
        except Exception as e:
            logger.error(f"æ ¼å¼éªŒè¯å¤±è´¥: {e}")
            return {
                'is_valid': False,
                'format_errors': [f'format_validation_error: {str(e)}']
            }
    
    def _validate_state_format(self, state: Dict[str, Any]) -> List[str]:
        """éªŒè¯çŠ¶æ€æ ¼å¼"""
        errors = []
        
        try:
            # æ£€æŸ¥å«æ˜Ÿä½ç½®æ ¼å¼
            if 'satellite_positions' in state:
                positions = state['satellite_positions']
                if not isinstance(positions, list):
                    errors.append('invalid_satellite_positions_type')
                else:
                    for i, pos in enumerate(positions):
                        if not isinstance(pos, list) or len(pos) != 3:
                            errors.append(f'invalid_satellite_position_{i}')
                        elif not all(isinstance(x, (int, float)) and np.isfinite(x) for x in pos):
                            errors.append(f'invalid_satellite_position_values_{i}')
            
            # æ£€æŸ¥å¯¼å¼¹ä½ç½®æ ¼å¼
            if 'missile_positions' in state:
                positions = state['missile_positions']
                if not isinstance(positions, list):
                    errors.append('invalid_missile_positions_type')
                else:
                    for i, pos in enumerate(positions):
                        if not isinstance(pos, list) or len(pos) != 3:
                            errors.append(f'invalid_missile_position_{i}')
                        elif not all(isinstance(x, (int, float)) and np.isfinite(x) for x in pos):
                            errors.append(f'invalid_missile_position_values_{i}')
            
            # æ£€æŸ¥å¯è§æ€§çŸ©é˜µæ ¼å¼
            if 'visibility_matrix' in state:
                matrix = state['visibility_matrix']
                if not isinstance(matrix, list):
                    errors.append('invalid_visibility_matrix_type')
                else:
                    for i, row in enumerate(matrix):
                        if not isinstance(row, list):
                            errors.append(f'invalid_visibility_matrix_row_{i}')
                        elif not all(isinstance(x, (int, bool)) for x in row):
                            errors.append(f'invalid_visibility_matrix_values_{i}')
            
        except Exception as e:
            errors.append(f'state_format_error: {str(e)}')
        
        return errors
    
    def _validate_action_format(self, action: Dict[str, Any]) -> List[str]:
        """éªŒè¯åŠ¨ä½œæ ¼å¼"""
        errors = []
        
        try:
            # æ£€æŸ¥å«æ˜ŸåŠ¨ä½œæ ¼å¼
            if 'satellite_actions' in action:
                sat_actions = action['satellite_actions']
                if not isinstance(sat_actions, dict):
                    errors.append('invalid_satellite_actions_type')
                else:
                    for sat_id, sat_action in sat_actions.items():
                        if not isinstance(sat_action, dict):
                            errors.append(f'invalid_satellite_action_{sat_id}')
            
            # æ£€æŸ¥ä»»åŠ¡åŠ¨ä½œæ ¼å¼
            if 'mission_actions' in action:
                mission_actions = action['mission_actions']
                if not isinstance(mission_actions, dict):
                    errors.append('invalid_mission_actions_type')
                else:
                    # æ£€æŸ¥ç›®æ ‡åˆ†é…æ ¼å¼
                    if 'target_assignments' in mission_actions:
                        assignments = mission_actions['target_assignments']
                        if not isinstance(assignments, list):
                            errors.append('invalid_target_assignments_type')
                        else:
                            for i, assignment in enumerate(assignments):
                                if not isinstance(assignment, dict):
                                    errors.append(f'invalid_target_assignment_{i}')
                                elif not all(key in assignment for key in ['satellite_id', 'target_id']):
                                    errors.append(f'incomplete_target_assignment_{i}')
            
        except Exception as e:
            errors.append(f'action_format_error: {str(e)}')
        
        return errors
    
    def _check_physical_constraints(self, data_point) -> Dict[str, Any]:
        """æ£€æŸ¥ç‰©ç†çº¦æŸ"""
        try:
            constraint_violations = []
            
            if hasattr(data_point, 'state'):
                state = data_point.state
                
                # æ£€æŸ¥ä½ç½®çº¦æŸ
                if self.validation_rules.get('position_bounds', False):
                    pos_violations = self._check_position_bounds(state)
                    constraint_violations.extend(pos_violations)
                
                # æ£€æŸ¥é€Ÿåº¦çº¦æŸ
                if self.validation_rules.get('velocity_limits', False):
                    vel_violations = self._check_velocity_limits(state)
                    constraint_violations.extend(vel_violations)
                
                # æ£€æŸ¥å§¿æ€çº¦æŸ
                if self.validation_rules.get('attitude_constraints', False):
                    att_violations = self._check_attitude_constraints(state)
                    constraint_violations.extend(att_violations)
            
            return {
                'is_valid': len(constraint_violations) == 0,
                'constraint_violations': constraint_violations
            }
            
        except Exception as e:
            logger.error(f"ç‰©ç†çº¦æŸæ£€æŸ¥å¤±è´¥: {e}")
            return {
                'is_valid': False,
                'constraint_violations': [f'physics_check_error: {str(e)}']
            }
    
    def _check_position_bounds(self, state: Dict[str, Any]) -> List[str]:
        """æ£€æŸ¥ä½ç½®è¾¹ç•Œ"""
        violations = []
        
        try:
            earth_radius = self.physical_constraints['position_bounds']['earth_radius']
            min_altitude = self.physical_constraints['position_bounds']['min_altitude']
            max_altitude = self.physical_constraints['position_bounds']['max_altitude']
            
            # æ£€æŸ¥å«æ˜Ÿä½ç½®
            if 'satellite_positions' in state:
                for i, pos in enumerate(state['satellite_positions']):
                    if len(pos) >= 3:
                        x, y, z = pos[0], pos[1], pos[2]
                        distance = np.sqrt(x*x + y*y + z*z)
                        altitude = distance - earth_radius
                        
                        if altitude < min_altitude:
                            violations.append(f'satellite_{i}_altitude_too_low: {altitude:.1f}km')
                        elif altitude > max_altitude:
                            violations.append(f'satellite_{i}_altitude_too_high: {altitude:.1f}km')
            
            # æ£€æŸ¥å¯¼å¼¹ä½ç½®
            if 'missile_positions' in state:
                for i, pos in enumerate(state['missile_positions']):
                    if len(pos) >= 3:
                        x, y, z = pos[0], pos[1], pos[2]
                        distance = np.sqrt(x*x + y*y + z*z)
                        altitude = distance - earth_radius
                        
                        if altitude < -1.0:  # å…è®¸è½»å¾®çš„åœ°ä¸‹ä½ç½®ï¼ˆæ•°å€¼è¯¯å·®ï¼‰
                            violations.append(f'missile_{i}_underground: {altitude:.1f}km')
                        elif altitude > max_altitude:
                            violations.append(f'missile_{i}_altitude_too_high: {altitude:.1f}km')
            
        except Exception as e:
            violations.append(f'position_bounds_error: {str(e)}')
        
        return violations
    
    def _check_velocity_limits(self, state: Dict[str, Any]) -> List[str]:
        """æ£€æŸ¥é€Ÿåº¦é™åˆ¶"""
        violations = []
        
        try:
            max_orbital_vel = self.physical_constraints['velocity_limits']['max_orbital_velocity']
            max_missile_vel = self.physical_constraints['velocity_limits']['max_missile_velocity']
            
            # æ£€æŸ¥å«æ˜Ÿé€Ÿåº¦
            if 'satellite_velocities' in state:
                for i, vel in enumerate(state['satellite_velocities']):
                    if len(vel) >= 3:
                        vx, vy, vz = vel[0], vel[1], vel[2]
                        speed = np.sqrt(vx*vx + vy*vy + vz*vz)
                        
                        if speed > max_orbital_vel:
                            violations.append(f'satellite_{i}_speed_too_high: {speed:.2f}km/s')
            
            # æ£€æŸ¥å¯¼å¼¹é€Ÿåº¦
            if 'missile_velocities' in state:
                for i, vel in enumerate(state['missile_velocities']):
                    if len(vel) >= 3:
                        vx, vy, vz = vel[0], vel[1], vel[2]
                        speed = np.sqrt(vx*vx + vy*vy + vz*vz)
                        
                        if speed > max_missile_vel:
                            violations.append(f'missile_{i}_speed_too_high: {speed:.2f}km/s')
            
        except Exception as e:
            violations.append(f'velocity_limits_error: {str(e)}')
        
        return violations
    
    def _check_attitude_constraints(self, state: Dict[str, Any]) -> List[str]:
        """æ£€æŸ¥å§¿æ€çº¦æŸ"""
        violations = []
        
        try:
            tolerance = self.physical_constraints['attitude_constraints']['quaternion_norm_tolerance']
            
            # æ£€æŸ¥å«æ˜Ÿå§¿æ€
            if 'satellite_attitudes' in state:
                for i, att in enumerate(state['satellite_attitudes']):
                    if len(att) >= 4:
                        q0, q1, q2, q3 = att[0], att[1], att[2], att[3]
                        norm = np.sqrt(q0*q0 + q1*q1 + q2*q2 + q3*q3)
                        
                        if abs(norm - 1.0) > tolerance:
                            violations.append(f'satellite_{i}_quaternion_norm_invalid: {norm:.3f}')
            
        except Exception as e:
            violations.append(f'attitude_constraints_error: {str(e)}')
        
        return violations
    
    def _check_temporal_consistency(self, data_point) -> Dict[str, Any]:
        """æ£€æŸ¥æ—¶é—´ä¸€è‡´æ€§"""
        try:
            inconsistencies = []
            
            if not hasattr(data_point, 'timestamp'):
                inconsistencies.append('missing_timestamp')
                return {
                    'is_consistent': False,
                    'inconsistencies': inconsistencies
                }
            
            current_time = data_point.timestamp
            
            # æ£€æŸ¥ä¸å†å²æ•°æ®çš„æ—¶é—´é—´éš”
            if self.historical_data:
                last_time = self.historical_data[-1]['timestamp']
                time_gap = (current_time - last_time).total_seconds()
                
                max_gap = self.physical_constraints['temporal_constraints']['max_time_gap']
                min_step = self.physical_constraints['temporal_constraints']['min_time_step']
                
                if time_gap > max_gap:
                    inconsistencies.append(f'time_gap_too_large: {time_gap:.1f}s')
                elif time_gap < min_step:
                    inconsistencies.append(f'time_step_too_small: {time_gap:.1f}s')
            
            return {
                'is_consistent': len(inconsistencies) == 0,
                'inconsistencies': inconsistencies
            }
            
        except Exception as e:
            logger.error(f"æ—¶é—´ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return {
                'is_consistent': False,
                'inconsistencies': [f'temporal_check_error: {str(e)}']
            }
    
    def _detect_anomalies(self, data_point) -> Dict[str, Any]:
        """æ£€æµ‹å¼‚å¸¸"""
        try:
            anomalies = []
            anomaly_score = 0.0
            
            if len(self.historical_data) < 10:
                # å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå¼‚å¸¸æ£€æµ‹
                return {
                    'anomalies': [],
                    'anomaly_score': 0.0
                }
            
            # ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹
            if self.anomaly_detection.get('statistical_outliers', False):
                stat_anomalies = self._detect_statistical_outliers(data_point)
                anomalies.extend(stat_anomalies)
            
            # ç‰©ç†å¼‚å¸¸æ£€æµ‹
            if self.anomaly_detection.get('physical_constraints', False):
                phys_anomalies = self._detect_physical_anomalies(data_point)
                anomalies.extend(phys_anomalies)
            
            # æ—¶é—´å¼‚å¸¸æ£€æµ‹
            if self.anomaly_detection.get('temporal_anomalies', False):
                temp_anomalies = self._detect_temporal_anomalies(data_point)
                anomalies.extend(temp_anomalies)
            
            # è®¡ç®—å¼‚å¸¸åˆ†æ•°
            anomaly_score = len(anomalies) / 10.0  # ç®€åŒ–çš„å¼‚å¸¸åˆ†æ•°
            
            return {
                'anomalies': anomalies,
                'anomaly_score': min(1.0, anomaly_score)
            }
            
        except Exception as e:
            logger.error(f"å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")
            return {
                'anomalies': [f'anomaly_detection_error: {str(e)}'],
                'anomaly_score': 1.0
            }
    
    def _detect_statistical_outliers(self, data_point) -> List[str]:
        """æ£€æµ‹ç»Ÿè®¡å¼‚å¸¸å€¼"""
        outliers = []
        
        try:
            if not hasattr(data_point, 'reward'):
                return outliers
            
            # æ”¶é›†å†å²å¥–åŠ±æ•°æ®
            historical_rewards = [record['reward'] for record in self.historical_data 
                                if 'reward' in record]
            
            if len(historical_rewards) < 5:
                return outliers
            
            # è®¡ç®—ç»Ÿè®¡é‡
            mean_reward = np.mean(historical_rewards)
            std_reward = np.std(historical_rewards)
            
            # 3-sigmaè§„åˆ™æ£€æµ‹å¼‚å¸¸
            if abs(data_point.reward - mean_reward) > 3 * std_reward:
                outliers.append(f'reward_outlier: {data_point.reward:.3f} vs mean {mean_reward:.3f}')
            
        except Exception as e:
            outliers.append(f'statistical_outlier_error: {str(e)}')
        
        return outliers
    
    def _detect_physical_anomalies(self, data_point) -> List[str]:
        """æ£€æµ‹ç‰©ç†å¼‚å¸¸"""
        anomalies = []
        
        try:
            if not hasattr(data_point, 'state'):
                return anomalies
            
            state = data_point.state
            
            # æ£€æµ‹ä½ç½®è·³è·ƒ
            if 'satellite_positions' in state and self.historical_data:
                last_state = self.historical_data[-1].get('state', {})
                last_positions = last_state.get('satellite_positions', [])
                
                current_positions = state['satellite_positions']
                
                for i, (curr_pos, last_pos) in enumerate(zip(current_positions, last_positions)):
                    if len(curr_pos) >= 3 and len(last_pos) >= 3:
                        distance = np.sqrt(sum((c - l)**2 for c, l in zip(curr_pos, last_pos)))
                        
                        # æ£€æµ‹å¼‚å¸¸å¤§çš„ä½ç½®å˜åŒ–ï¼ˆå‡è®¾æœ€å¤§é€Ÿåº¦15km/sï¼Œæ—¶é—´é—´éš”300sï¼‰
                        max_distance = 15.0 * 300.0  # km
                        if distance > max_distance:
                            anomalies.append(f'satellite_{i}_position_jump: {distance:.1f}km')
            
        except Exception as e:
            anomalies.append(f'physical_anomaly_error: {str(e)}')
        
        return anomalies
    
    def _detect_temporal_anomalies(self, data_point) -> List[str]:
        """æ£€æµ‹æ—¶é—´å¼‚å¸¸"""
        anomalies = []
        
        try:
            if not hasattr(data_point, 'timestamp') or not self.historical_data:
                return anomalies
            
            current_time = data_point.timestamp
            last_time = self.historical_data[-1]['timestamp']
            
            # æ£€æµ‹æ—¶é—´å€’é€€
            if current_time < last_time:
                anomalies.append(f'time_regression: {current_time} < {last_time}')
            
        except Exception as e:
            anomalies.append(f'temporal_anomaly_error: {str(e)}')
        
        return anomalies
    
    def _calculate_quality_score(self, validation_result: Dict[str, Any]) -> float:
        """è®¡ç®—è´¨é‡åˆ†æ•°"""
        try:
            score = 1.0
            
            # åŸºäºé”™è¯¯æ•°é‡é™ä½åˆ†æ•°
            error_count = len(validation_result.get('errors', []))
            warning_count = len(validation_result.get('warnings', []))
            anomaly_count = len(validation_result.get('anomalies', []))
            
            # é”™è¯¯ä¸¥é‡å½±å“åˆ†æ•°
            score -= error_count * 0.3
            
            # è­¦å‘Šè½»å¾®å½±å“åˆ†æ•°
            score -= warning_count * 0.1
            
            # å¼‚å¸¸å½±å“åˆ†æ•°
            score -= anomaly_count * 0.05
            
            # åŸºäºè´¨é‡æŒ‡æ ‡è°ƒæ•´åˆ†æ•°
            quality_metrics = validation_result.get('quality_metrics', {})
            
            if 'completeness' in quality_metrics:
                completeness_score = quality_metrics['completeness'].get('completeness_score', 1.0)
                score *= completeness_score
            
            return max(0.0, min(1.0, score))
            
        except Exception as e:
            logger.error(f"è´¨é‡åˆ†æ•°è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def _check_field_exists(self, data_point, field_path: str) -> bool:
        """æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨"""
        try:
            parts = field_path.split('.')
            current = data_point
            
            for part in parts:
                if hasattr(current, part):
                    current = getattr(current, part)
                elif isinstance(current, dict) and part in current:
                    current = current[part]
                else:
                    return False
            
            return current is not None
            
        except Exception:
            return False
    
    def _update_historical_data(self, data_point, validation_result: Dict[str, Any]):
        """æ›´æ–°å†å²æ•°æ®"""
        try:
            record = {
                'timestamp': data_point.timestamp if hasattr(data_point, 'timestamp') else datetime.now(),
                'reward': data_point.reward if hasattr(data_point, 'reward') else 0.0,
                'state': data_point.state if hasattr(data_point, 'state') else {},
                'validation_score': validation_result['validation_score']
            }
            
            self.historical_data.append(record)
            
            # é™åˆ¶å†å²æ•°æ®å¤§å°
            if len(self.historical_data) > self.max_history_size:
                self.historical_data = self.historical_data[-self.max_history_size:]
                
        except Exception as e:
            logger.error(f"å†å²æ•°æ®æ›´æ–°å¤±è´¥: {e}")
    
    def get_validation_statistics(self) -> Dict[str, Any]:
        """è·å–éªŒè¯ç»Ÿè®¡ä¿¡æ¯"""
        try:
            total = self.validation_stats['total_validations']
            
            if total == 0:
                return {
                    'total_validations': 0,
                    'success_rate': 0.0,
                    'average_quality_score': 0.0
                }
            
            success_rate = self.validation_stats['passed_validations'] / total
            
            # è®¡ç®—å¹³å‡è´¨é‡åˆ†æ•°
            if self.historical_data:
                quality_scores = [record['validation_score'] for record in self.historical_data 
                                if 'validation_score' in record]
                avg_quality = np.mean(quality_scores) if quality_scores else 0.0
            else:
                avg_quality = 0.0
            
            return {
                'total_validations': total,
                'passed_validations': self.validation_stats['passed_validations'],
                'failed_validations': self.validation_stats['failed_validations'],
                'success_rate': success_rate,
                'anomaly_detections': self.validation_stats['anomaly_detections'],
                'average_quality_score': avg_quality,
                'historical_data_size': len(self.historical_data)
            }
            
        except Exception as e:
            logger.error(f"éªŒè¯ç»Ÿè®¡è®¡ç®—å¤±è´¥: {e}")
            return {'total_validations': 0}
    
    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.validation_stats = {
            'total_validations': 0,
            'passed_validations': 0,
            'failed_validations': 0,
            'anomaly_detections': 0,
            'data_quality_score': 1.0
        }
        self.historical_data = []
        logger.info("éªŒè¯ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
